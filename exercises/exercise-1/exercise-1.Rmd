---
title: "Exercise 1: Amphibian occupancy in the fragmented Brazilian Atlantic Forest"
author: "Jeffrey W. Doser and Elise F. Zipkin"
date: "November 9, 2023"
output: html_document
bibliography: [references.bib]
biblio-style: apalike
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
```

\newcommand{\bm}{\boldsymbol}

## Introduction

In this exercise, we will use single-species nonspatial and spatial occupancy models to explore the effects of landscape fragmentation and topography on a tropical amphibian species *Crossodactylus caramaschii* in the fragmented Brazilian Atlantic Forest. These data come from @ribeiro2018effects, in which the authors used a multi-species occupancy model to quantify effects of agriculture and topography for a community of tropical amphibians. Here we will use data from a single species, *Crossodactylus caramaschii*, and will compare a series of different single-species occupancy models in their ability to explain spatial variation in where the species occurs across the fragmented landscape. Note that here we are only using data obtained via passive acoustic monitoring, whereas the complete analysis in @ribeiro2018effects used data from both passive acoustic monitoring and active transect sampling.

We first load `spOccupancy` as well as a few other packages we will use for summarizing model output and generating visualizations. We also set the seed so we can all get the same exact results.

```{r}
set.seed(100)
library(spOccupancy)
library(MCMCvis)
library(ggplot2)
library(sf)
# If not using the RStudio project, set working directory to the exercise-1 directory 
# directory.
```

## Data prep and exploratory data analysis

The data are stored in an R data file object called `amphibian-data.rda`. We load this object below, which reads in a list called `data.crocar`.

```{r}
load("amphibian-data.rda")
# Check out the structure of the list
str(data.crocar)
```

The `data.crocar` object is stored in the exact format required for fitting single-species occupancy models in `spOccupancy`. The list is comprised of four objects: 

1. `y`: the detection-nondetection data. This is a matrix or data frame of the detection-nondetection data where the rows correspond to sites and the columns correspond to visits. Note that for imbalanced data sets where each site may not have the same number of visits, `NA` values should be placed in those site/visit combinations without any data. 
2. `occ.covs`: the covariates for use in the occupancy portion of the model. This is a data frame or matrix of covariates, with each row corresponding to a site, and each column corresponding to a different variable. 
3. `det.covs`: the covariates for use in the detection portion of the model. This is a list, where each element of the list corresponds to a different covariate. Covariates on detection can be either site-level or observation-level. For site-level covariates, they should be specified as a vector with length equal to the total number of sites in the data set. For observation-level covariates, they should be specified as a matrix with rows corresponding to sites and columns corresponding to visit. Here we have two observation-level covariates.
4. `coords`: the spatial coordinates of the sites. This is a matrix with rows corresponding to sites and two columns corresponding to the easting and northing coordinates of each given location. Note that `spOccupancy` assumes the coordinates are in a projected coordinate system (i.e., not latitude/longitude). The `coords` component is only required for spatially-explicit models in `spOccupancy`.

In all exercises in this course, data will be provided in the format necessary for fitting models in `spOccupancy`. For guidance on formatting raw data sets into `spOccupancy` format, see [this vignette on the package website](https://www.jeffdoser.com/files/spoccupancy-web/articles/dataformatting). 

To get an initial sense of how common our species is, below we generate an exploratory plot showing the locations across the landscape where the species was detected at least once. 

```{r, fig.fullwidth = TRUE, fig.align = 'center'}
# 1 if species was ever detected, 0 if not
y.max <- apply(data.crocar$y, 1, max, na.rm = TRUE)
plot.df <- data.frame(val = y.max,
                      x = data.crocar$coords[, 1],
                      y = data.crocar$coords[, 2])
# Convert value to factor
plot.df$val <- factor(ifelse(plot.df$val == 1, 'Observed', 'Not Observed'))
plot.sf <- st_as_sf(plot.df, 
                    coords = c('x', 'y'), 
                    crs = 29101)
ggplot() +
  geom_sf(data = plot.sf, aes(col = val)) +
  scale_color_viridis_d() +
  theme_bw(base_size = 15) +
  labs(x = "Longitude", y = "Latitude", col = "")
```

We see *Crossodactylus caramaschii* is detected primarily in the western portion of the study area.

## Non-spatial occupancy models

Now that the data are formatted in the necessary format for use with `spOccupancy`, we are now set to start fitting some models. The function to fit a non-spatial single-species occupancy model is `PGOcc()`. The manual page for `PGOcc()` provides details on the different function arguments. Below we fit an occupancy model with two covariates in our model for occupancy, and three covariates in our model for detection probability. Note the use of the `scale()` function directly in the model formulas, which will standardize each covariate to have a mean of 0 and standard deviation of 1 when fitting the model. We often recommend standardizing variables when fitting models, as it can often be essential for adequate convergence of the MCMC algorithms, particularly if the covariates you desire to include in the model have very different magnitudes. 

We will fit a model with two covariates (forest cover and stream density) on occupancy probability and two covariates (date and rain) on detection probability (including both a linear and quadratic effect of date). Below we provide the complete statistical model we will fit, followed by the corresponding code to fit the model in `spOccupancy`. 

\begin{aligned}
  y_{j, k} &\sim \text{Bernoulli}(z_j \cdot p_{j, k}) \\
  \text{logit}(p_{j, k}) &= \alpha_0 + \alpha_1 \cdot \text{DAY}_{j, k} + \alpha_2 \cdot \text{DAY}^2_{j, k} + \alpha_3 \cdot \text{RAIN}_{j, k} \\
  z_j &\sim \text{Bernoulli}(\psi_j) \\
  \text{logit}(\psi_j) &= \beta_0 + \beta_1 \cdot \text{FOREST}_j + \beta_2 \cdot \text{DENSITY}_j \\
  \beta_r &\sim \text{Normal}(0, 2.72) \\
  \alpha_r &\sim \text{Normal}(0, 2.72)
\end{aligned}

```{r}
# Fit a non-spatial, single-species occupancy model.
out.0 <- PGOcc(occ.formula = ~ scale(forest) + scale(density),
               det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
               data = data.crocar,
               n.samples = 10000,
               n.thin = 5,
               verbose = TRUE,
               n.burn = 5000,
               n.chains = 3,
               n.report = 2000)
# Quick summary of the model results.
summary(out.0)
```

Notice in the above model output, we get messages that we did not specify any prior distributions or initial values for the parameters in our model. By default, `spOccupancy` will assign vague normal prior distributions for the occurrence and detection regression coefficients. The algorithm that `spOccupancy` uses underneath the hood requires us to use normal prior distributions for the regression coefficients. We can specify the values of the prior distribution using the `priors` argument. Below we set the priors for both occurrence and regression coefficients to have a mean of 0 and a variance of 2.72. This results in a relatively uniform prior on the probability scale [@northrup2018comment]. 

```{r}
# Prior distributions
priors <- list(beta.normal = list(mean = 0, var = 2.72),
               alpha.normal = list(mean = 0, var = 2.72))
```

We can additionally specify initial values for the occurrence (`beta`) and detection (`alpha`) regression coefficients, as well as the latent occupancy values (`z`) in the `inits` argument. For single-species occupancy models fit in `spOccupancy`, specifying the initial values is largely inconsequential. In the following code chunk, we explicitly specify the prior distributions and initial values, then rerun the model with these arguments.

```{r}
# Initial values
inits <- list(beta = 0, alpha = 0, z = apply(data.crocar$y, 1, max, na.rm = TRUE)) 
# Refit the model with explicit specification of priors and inits
out.1 <- PGOcc(occ.formula = ~ scale(forest) + scale(density),
               det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
               data = data.crocar,
               priors = priors, 
               inits = inits,
               n.samples = 10000,
               n.thin = 5,
               verbose = TRUE,
               n.burn = 5000,
               n.chains = 3,
               n.report = 2000)
# Summary
summary(out.1)
```

The model output provides a summary of the occurrence and detection parameters, as well as information on convergence diagnostics. Here, we see all Rhat values are less than 1.1 and all ESS values are quite large, indicating adequate convergence and mixing of the MCMC chains. We see a strong negative effect of forest cover on occurrence probability, as well as a positive effect of stream density. 

We can also generate a simple traceplot of the model parameters to further diagnose convergence.

```{r, fig.fullwidth = TRUE, fig.align = 'center'}
# Traceplot of occurrence coefficients
plot(out.1, param = 'beta', density = FALSE)
# Traceplots of detection coefficients
plot(out.1, param = 'alpha', density = FALSE)
```

Here we see the traceplots show adequate mixing and all chains appear to have converged on the same values. Together with the Rhat and ESS values from the model summary, we have substantial evidence that our model has converged. 

The model objects can further be used with the `MCMCvis` package [@youngflesh2018mcmcvis] to create quick and simple visualizations of the estimated parameters. 

```{r}
# Occupancy covariate effects
MCMCplot(out.1$beta.samples, ref_ovl = TRUE, ci = c(50, 95),
         main = 'Occupancy Parameters')
# Detection covariate effects
MCMCplot(out.1$alpha.samples, ref_ovl = TRUE, ci = c(50, 95), 
         main = 'Detection Parameters')
```

We next will fit an alternative model that assumes occupancy probability is constant across the 50 locations to compare with our previous model. 

```{r}
# Fit model assuming constant occupancy probability
# Note that verbose = FALSE to hide printed model progress
out.2 <- PGOcc(occ.formula = ~ 1,
               det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
               data = data.crocar,
               priors = priors, 
               inits = inits,
               n.samples = 10000,
               n.thin = 5,
               verbose = FALSE,
               n.burn = 5000,
               n.chains = 3,
               n.report = 2000)
# Check convergence
summary(out.2)
```

`spOccupancy` provides two approaches for model comparison: the Widely Applicable Information Criterion (WAIC) and k-fold cross-validation. Model comparison using WAIC is accomplished using the `waicOcc()` function.

```{r}
# WAIC for the model with occupancy covariates
waicOcc(out.1)
# WAIC for the model without occupancy covariates
waicOcc(out.2)
```

Model comparison usng WAIC is similar to classical model comparison using AIC: the lower the value the better. Here we see the WAIC for the model with forest cover and stream density has a lower WAIC, providing evidence that occupancy probability is not constant across the 50 sites. 

K-fold cross-validation is accomplished using the argument `k.fold` in `PGOcc()`. Compared to WAIC, this approach is more so a direct assessment of a model's ability to predict at locations not used when fitting the model. The basic idea of k-fold cross-validation is that we will 

1. Split the data into $k$ subsets 
2. Fit the data using $k - 1$ of the subsets
3. Predict $y_{j, k}$ at the locations not used to fit the model 
4. Calculate some criterion to assess model predictive performance 
5. Repeat 2-4 for each of the $k$ subsets and ultimately average the model performance values calculated in step 4 for an overall measure of model predictive performance. 

This can be done either directly when fitting the model, or can be done separately by specifying `k.fold.only = TRUE`. Below, we perform three-fold cross-validation for both models. We use the `k.fold.threads` argument to do this in parallel across 3 threads.

```{r}
k.fold.1 <- PGOcc(occ.formula = ~ scale(forest) + scale(density),
                  det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
                  data = data.crocar,
                  priors = priors, 
                  inits = inits,
                  n.samples = 10000,
                  n.thin = 5,
                  verbose = FALSE,
                  n.burn = 5000,
                  n.chains = 3,
                  n.report = 2000, 
                  k.fold = 3, 
                  k.fold.threads = 3,
                  k.fold.only = TRUE)
k.fold.2 <- PGOcc(occ.formula = ~ 1,
                  det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
                  data = data.crocar,
                  priors = priors, 
                  inits = inits,
                  n.samples = 10000,
                  n.thin = 5,
                  verbose = FALSE,
                  n.burn = 5000,
                  n.chains = 3,
                  n.report = 2000, 
                  k.fold = 3, 
                  k.fold.threads = 3,
                  k.fold.only = TRUE)
# Model with occupancy covariates
k.fold.1$k.fold.deviance
# Model without occupancy covariates
k.fold.2$k.fold.deviance
```

`spOccupancy` uses model deviance as a model comparison metric when performing cross-validation, which is interpreted similarly to WAIC: smaller values indicate superior model predictive performance. We again see the model with two occupancy covariates outperforms the model that assumes constant occupancy probability across space.

Now that we have our top performing model, we can perform a posterior predictive check using the `ppcOcc()` function. A posterior predictive check (PPC) serves as a Goodness of Fit (GoF) assessment, analogous to a residual check when fitting a basic linear model. Our goal is to assess how closely data predicted from the model we fit align with the true data that were collected. If there are drastic differences in the true data from the model generated data, our model likely is not very useful. For binary data, we need to somehow "group" the data before doing a posterior predictive check, and then compare the "grouped" real data to the "grouped" replicate data that we generate from our model. In `spOccupancy`, our posterior predictive checks broadly take the following form: 

1. Fit the model using any of the model-fitting functions (here `PGOcc()`), which generates replicated values for all detection-nondetection data points.
2. Bin both the actual and the replicated detection-nondetection data in a suitable manner, such as by site or replicate
3. Compute a fit statistic on both the actual data and also on the model-generated 'replicate data'.
4. Compare the fit statistics for the true data and replicate data. If they are widely different, this suggests a lack of fit of the model to the actual data set at hand. 

Below we group the data by site (i.e., we sum all the detection-nondetection values over the repeat visits for each site), and perform a posterior predictive check using a Freeman-Tukey statistic.  

```{r}
out.ppc <- ppcOcc(out.1, fit.stat = 'freeman-tukey', group = 1)
str(out.ppc)
```

The `out.ppc` object contains a variety of objects, which can all be explored to thoroughly understand how well the model fits the data. A simple approach to summarizing a posterior predictive check is to use a Bayesian p-value. A Bayesian p-value is the probability, under the fitted model, to obtain a value of the fit statistic that is more extreme (i.e., larger) than the one observed, i.e., for the actual data. A Bayesian p-value that hovers around 0.5 indicates adequate model fit, while values less than 0.1 or greater than 0.9 suggest our model does not fit the data well. We can calculate a Bayesian p-value using the `summary()` function.

```{r}
summary(out.ppc)
```

Here our Bayesian p-value is about 0.23, indicating adequate model fit. Much more detail on posterior predictive checks in `spOccupancy` can be found in the [introductory package vignette](https://www.jeffdoser.com/files/spoccupancy-web/articles/modelfitting#posterior-predictive-checks).

Finally, we can generate some figures to visualize the results. Below we extract the mean occupancy probabilities at each site, and subsequently plot the occupancy probabilities in a map. 

```{r}
# The full posterior distribution of site-level occupancy probabilities
str(out.1$psi.samples)
# Get the mean occupancy probability at each site
psi.means <- apply(out.1$psi.samples, 2, mean)
# Generate data frame for making a map
plot.df <- data.frame(psi.means = psi.means,
                      x = data.crocar$coords[, 1],
                      y = data.crocar$coords[, 2])
# Convert to an sf object to make a map
plot.sf <- st_as_sf(plot.df, coords = c('x', 'y'), crs = 29101)
ggplot() +
  geom_sf(data = plot.sf, aes(fill = psi.means), pch = 21, size = 4) +
  scale_fill_viridis_c() +
  theme_bw(base_size = 15) +
  labs(x = "Longitude", y = "Latitude", fill = '', title = 'Mean Occupancy Probability')
```

Thinking back to our plot of the observed data, this plot makes sense as we see fairly high occupancy probability estimates in the western portion of the study area, and low occupancy probability in the southeastern sites.

The `predict()` function can be used to predict occupancy probability across a region of interest. For example, if we had covariate values of forest cover and stream density across the study area, we could predict occupancy probability across a grid and ultimately generate a species distribution map. We will see how to accomplish such a task in the next two exercises. Here, we will use `predict()` to generate a marginal effects plot for the effect of forest cover and stream density on occupancy probability.  

```{r, fig.fullwidth = TRUE, fig.align = 'center'}
# Marginal effects plot for forest cover ----------------------------------
# Create a set of values across the range of observed forest values
forest.pred.vals <- seq(min(data.crocar$occ.covs$forest),
                        max(data.crocar$occ.covs$forest),
                        length.out = 100)

# Scale predicted values by mean and standard deviation used to fit the model
forest.pred.vals.scale <- (forest.pred.vals - mean(data.crocar$occ.covs$forest)) /
                           sd(data.crocar$occ.covs$forest)
# Predict occupancy across forest values at mean value of stream density
X.0 <- as.matrix(data.frame(intercept = 1, 
                            forest = forest.pred.vals.scale,
                            density = 0))
str(X.0)
out.pred <- predict(out.1, X.0)
str(out.pred)
# Calculate median and 95% credible interval quantiles for occ prob
psi.0.quants <- apply(out.pred$psi.0.samples, 2, quantile,
                      prob = c(0.025, 0.5, 0.975))
# Put it all in a data frame for plotting
psi.plot.dat <- data.frame(psi.med = psi.0.quants[2, ],
                           psi.low = psi.0.quants[1, ],
                           psi.high = psi.0.quants[3, ],
                           forest = forest.pred.vals)
forest.plot <- ggplot(psi.plot.dat, aes(x = forest, y = psi.med)) +
  geom_ribbon(aes(ymin = psi.low, ymax = psi.high), fill = 'grey70') +
  geom_line() +
  theme_bw() +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = 'Forest (% cover)', y = 'Occupancy Probability')
# Marginal effects plot for stream density --------------------------------
density.pred.vals <- seq(min(data.crocar$occ.covs$density),
                         max(data.crocar$occ.covs$density),
                         length.out = 100)
density.pred.vals.scale <- (density.pred.vals - mean(data.crocar$occ.covs$density)) /
                            sd(data.crocar$occ.covs$density)
X.0 <- as.matrix(data.frame(intercept = 1, 
                            forest = 0, 
                            density = density.pred.vals.scale))
out.pred <- predict(out.1, X.0)
psi.0.quants <- apply(out.pred$psi.0.samples, 2, quantile,
                      prob = c(0.025, 0.5, 0.975))
psi.plot.dat <- data.frame(psi.med = psi.0.quants[2, ],
                           psi.low = psi.0.quants[1, ],
                           psi.high = psi.0.quants[3, ],
                           density = density.pred.vals)
density.plot <- ggplot(psi.plot.dat, aes(x = density, y = psi.med)) +
  geom_ribbon(aes(ymin = psi.low, ymax = psi.high), fill = 'grey70') +
  geom_line() +
  theme_bw() +
  scale_y_continuous(limits = c(0, 1)) +
  labs(x = 'Stream Density', y = 'Occupancy Probability')
forest.plot
density.plot
```

## 2b: Fitting spatial occupancy models

Next we fit a spatial occupancy model to explore if there is any residual spatial autocorrelation in occupancy probability that is not explained by the two covariates (forest cover and stream density) in the model. Below is the full statistical notation of the model we will fit, including prior distributions, which we specify below. 

\begin{aligned}
  y_{j, k} &\sim \text{Bernoulli}(z_j \cdot p_{j, k}) \\
  \text{logit}(p_{j, k}) &= \alpha_0 + \alpha_1 \cdot \text{DAY}_{j, k} + \alpha_2 \cdot \text{DAY}^2_{j, k} + \alpha_3 \cdot \text{RAIN}_{j, k} \\
  z_j &\sim \text{Bernoulli}(\psi_j) \\
  \text{logit}(\psi_j) &= \beta_0 + \beta_1 \cdot \text{FOREST}_j + \beta_2 \cdot \text{DENSITY}_j  + \text{w}_j\\
  \textbf{w} &\sim \text{NNGP}(\bm{0}, \bm{\Sigma}) \\
  \beta_r &\sim \text{Normal}(0, 2.72) \\
  \alpha_r &\sim \text{Normal}(0, 2.72) \\
  \phi &\sim \text{Uniform}(a_{\phi}, b_{\phi}) \\
  \sigma^2 &\sim \text{Inverse-Gamma}(a_{\sigma^2}, b_{\sigma^2})
\end{aligned}

The function to fit spatial occupancy models in `spOccupancy` is `spPGOcc()`. The syntax for fitting spatial occupancy models with `spPGOcc()` is quite similar to syntax used to fit regular occupancy models with `PGOcc()`. 

When fitting spatial occupancy models, the list of data (here called `data.crocar`) must also contain a two-dimensional matrix called `coords`, which contains the easting and northing (columns) coordinates for each of the sites (rows) in the data set. These spatial coordinates are needed to calculate the underlying spatial autocorrelation in occupancy probability between the sites (recall in the associated lecture that $\bm{\Sigma}$ depends on the distances between sites). 

```{r}
str(data.crocar)
# Coordinate system is EPSG:29101 (SAD69/Brazil Polyconic)
data.crocar$coords
```

Here we will use an exponential covariance function for the spatial random effects, which requires specifying priors for two additional parameters: $\sigma^2$ (the spatial variance parameter) and $\phi$ (the spatial decay parameter). For $\sigma^2$ we specify an inverse-Gamma prior with shape parameter equal to 2 and scale parameter equal to 1, which is a fairly vague prior that states the mean of the prior distribution is 1 with an infinite variance. For $\phi$, we specify a uniform prior. Recall that when using an exponential covariance function, the effective spatial range (or the distance at which spatial autocorrelation becomes very small (equal to 0.05)) is $\frac{3}{\phi}$. We will specify our prior on $\phi$ to say that the effective spatial range can be anywhere between the minimum distance between any two sites in the data set to the maximum distance between any two sites in the data set. This is a fairly vague prior that states the spatial autocorrelation can be fine-scale, broad-scale, or anywhere in between. Our priors for the occurrence and detection regression coefficients are the same as before. Note that all the prior distributions we specify below are the default prior values used by `spOccupancy` if we didn't explicitly include them in the function call to `spPGOcc`.

```{r}
# Get intersite distance matrix for specifying prior on phi
dist.mat <- dist(data.crocar$coords)
inits <- list(beta = 0, alpha = 0, z = apply(data.crocar$y, 1, max, na.rm = TRUE), 
              phi = 3 / mean(dist.mat), sigma.sq = 1,
              w = rep(0, nrow(data.crocar$y))) 
priors <- list(beta.normal = list(mean = 0, var = 2.72),
               alpha.normal = list(mean = 0, var = 2.72), 
               phi.unif = c(3 / max(dist.mat), 3 / min(dist.mat)), 
               sigma.sq.ig = c(2, 1))
```

The `NNGP` argument is used to specify whether or not we want to model spatial autocorrelation using a NNGP approach. For certain model types in `spOccupancy`, we can also fit models with a full Gaussian Process. Here we set `NNGP = TRUE` to use an NNGP, and will set the `n.neighbors` argument to 15 in order to use 15 neighbors in the approximation. Note that these are both default values in `spPGOcc` if they are not specified. 

The final difference between fitting spatial and non-spatial occupancy models in `spOccupancy` is how the number of MCMC samples is specified. For non-spatial models we simply specified the number of iterations/samples to fit using the `n.samples` argument. For spatial models in `spOccupancy`, the total number of MCMC samples is broken up into a set of "batches", where each batch has a set number of MCMC samples. We use this approach because the spatial decay parameter $\phi$ does not have a "nice" statistical algorithm like all other parameters in single-species occupancy models. In other words, at each MCMC iteration, we can propose a very good value for all other model parameters in spatial occupancy models, but the values we propose for $\phi$ are not as good, and so we may reject some of the values we propose. In order to make this update as efficient as possible, we run the MCMC algorithm in a series of "batches", where after each batch of MCMC samples, we will slightly adjust how we propose values for $\phi$ to try and make them as good as possible. More details on this approach can be found in the [introductory package vignette](https://www.jeffdoser.com/files/spoccupancy-web/articles/modelfitting#spPGOcc) as well as in @roberts2009examples for more complete statistical details on these so-called adaptive MCMC samplers. The total number of samples is equal to the total number of batches (`n.batch`) times the length of each batch (`batch.length`). Generally we recommend setting `batch.length = 25` and then adjusting `n.batch` to run the model long enough to achieve convergence. Here we run the model for three chains each with 20,000 samples (800 batches each with 25 samples), discard 10,000 samples as burn-in, and keep every 10th MCMC sample for a resulting 1000 samples per chain (3000 samples in total). 

```{r}
out.sp <- spPGOcc(occ.formula = ~ scale(forest) + scale(density),
                  det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
                  data = data.crocar,
                  NNGP = TRUE,
                  n.neighbors = 15,
                  cov.model = 'exponential',
                  priors = priors, 
                  inits = inits,
                  n.batch = 800,
                  batch.length = 25,
                  n.thin = 10,
                  n.burn = 10000,
                  n.chains = 3,
                  n.report = 200)
# Quick summary of model results.
summary(out.sp)
```

The spatial variance parameter gives us some indication of the amount of residual spatial variability in occupancy probability (after accounting for any covariates included in the model). Higher values indicate more variation, while values close to 0 indicate less variation (analogous to any other random effect variance). Here we see the spatial variance has large uncertainty, and so it is not immediately clear how much residual spatial variability there is in occupancy probability. Note this large amount of uncertainty is not too surprising given our data set. 50 locations is a fairly small number of locations to fit a spatial occupancy model, and so uncertainty of estimates in spatial models in such a situation will most likely be fairly substantial.  

The spatial decay parameter $\phi$ can provide us with intuition on the range of spatial autocorrelation. Recall when using an exponential covariance function, the effective spatial range is $\frac{3}{\phi}$. We calculate our estimated effective spatial range below. 

```{r}
# Spatial parameters
theta.means <- apply(out.sp$theta.samples, 2, mean)
theta.means
# Estimated effective spatial range
3 / theta.means[2]
```

Our estimate for the effective spatial range is in the units of the coordinate system in which the coordinates are supplied to the function. In this case, the coordinates were specified in meters, and so our estimate tells us the spatial autocorrelation drops to 5% at approximately `r round(3 / theta.means[2], 0)` meters. For this data set, that is a fairly small range, as each site is at minimum 250m apart from another. 
We further explore the spatial random effects by visualizing the estimates of the spatial random effects, which are stored in `out.sp$w.samples`. We do this first by plotting a histogram of their mean values, and second by plotting the mean values at each site in a map.

```{r, fig.fullwidth = TRUE, fig.align = 'center'}
# The spatial random effects
str(out.sp$w.samples)
# Get the mean of the spatial random effects
w.means <- apply(out.sp$w.samples, 2, mean)
# Simple histogram
hist(w.means)
# Generate data frame for making a map
plot.df <- data.frame(w.means = w.means,
                      x = data.crocar$coords[, 1],
                      y = data.crocar$coords[, 2])
# Convert to an sf object to make a map
plot.sf <- st_as_sf(plot.df, 
                    coords = c('x', 'y'), 
                    crs = 29101)
ggplot() +
  geom_sf(data = plot.sf, aes(fill = w.means), pch = 21, size = 4) +
  scale_fill_gradient2(midpoint = 0, low = '#B2182B', mid = 'white', high = '#2166AC',
                       na.value = NA) +
  theme_bw(base_size = 15) +
  labs(x = "Longitude", y = "Latitude", fill = '', title = 'Mean spatial random effect')

```

Most values seem pretty clustered around 0 perhaps suggesting minimal support for spatial autocorrelation. The map of the effects shows a fairly strong longitudinal gradient, with generally positive values in the west and negative values in the east. 

More formally, we can use WAIC or k-fold cross-validation to compare a spatial model with a non-spatial model. We compare the two models with WAIC and three-fold cross-validation.  


```{r}
# Non-spatial model
waicOcc(out.1)
# Spatial model
waicOcc(out.sp)
k.fold.sp <- spPGOcc(occ.formula = ~ scale(forest) + scale(density),
                     det.formula = ~ scale(date) + I(scale(date)^2) + scale(rain),
                     data = data.crocar,
                     NNGP = TRUE,
                     n.neighbors = 15,
                     cov.model = 'exponential',
                     priors = priors, 
                     inits = inits,
                     n.batch = 800,
                     batch.length = 25,
                     n.thin = 10,
                     n.burn = 10000,
                     n.chains = 3,
                     verbose = FALSE,
                     k.fold = 3, 
                     k.fold.threads = 3,
                     k.fold.only = TRUE)
# Spatial
k.fold.sp$k.fold.deviance
# Non-spatial
k.fold.1$k.fold.deviance
```

Here we see very similar WAIC and model deviance values between the two models. Since there is no large difference between them, we would consider the non-spatial model our final model if using these data in a formal analysis. 

# References {-}
